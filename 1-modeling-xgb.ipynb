{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenMIC-2018 baseline model\n",
    "\n",
    "First, make sure you [download the dataset](https://zenodo.org/record/1432913#.W6dPeJNKjOR)! and extract to the folder 'data'\n",
    "\n",
    "We'll load in the pre-computed [VGGish features](https://github.com/tensorflow/models/tree/master/research/audioset) and labels, and fit an [XgBoost](https://xgboost.readthedocs.io/en/stable/index.html) model for each of the 20 instrument classes using the pre-defined train-test splits provided in the repository.\n",
    "\n",
    "We'll then evaluate the models we fit, and show how to apply them to new audio signals.\n",
    "\n",
    "This notebook is not meant to demonstrate state-of-the-art performance on instrument recognition.  Rather, we hope that it can serve as a starting point for building your own instrument detectors without too much effort!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# These dependencies are necessary for loading the data\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "# Be sure to set this after downloading the dataset!\n",
    "DATA_ROOT = 'data'\n",
    "\n",
    "if not os.path.exists(DATA_ROOT):\n",
    "    raise ValueError('Did you forget to set `DATA_ROOT`?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "The openmic data is provided in a python-friendly format as `openmic-2018.npz`.\n",
    "\n",
    "You can load it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENMIC = np.load(os.path.join(DATA_ROOT, 'openmic-2018.npz'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y_true', 'Y_mask', 'sample_key']\n"
     ]
    }
   ],
   "source": [
    "# What's included?\n",
    "print(list(OPENMIC.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's included in the data?\n",
    "\n",
    "- `X`: 20000 * 10 * 128 array of VGGish features\n",
    "    - First index (0..19999) corresponds to the sample key\n",
    "    - Second index (0..9) corresponds to the time within the clip (each time slice is 960 ms long)\n",
    "    - Third index (0..127) corresponds to the VGGish features at each point in the 10sec clip\n",
    "    - Example `X[40, 8]` is the 128-dimensional feature vector for the 9th time slice in the 41st example\n",
    "- `Y_true`: 20000 * 20 array of *true* label probabilities\n",
    "    - First index corresponds to sample key, as above\n",
    "    - Second index corresponds to the label class (accordion, ..., voice)\n",
    "    - Example: `Y[40, 4]` indicates the confidence that example #41 contains the 5th instrument\n",
    "- `Y_mask`: 20000 * 20 binary mask values\n",
    "    - First index corresponds to sample key\n",
    "    - Second index corresponds to the label class\n",
    "    - Example: `Y[40, 4]` indicates whether or not we have observations for the 5th instrument for example #41\n",
    "- `sample_key`: 20000 array of sample key strings\n",
    "    - Example: `sample_key[40]` is the sample key for example #41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will be easier to use if we make direct variable names for everything\n",
    "X, Y_true, Y_mask, sample_key = OPENMIC['X'], OPENMIC['Y_true'], OPENMIC['Y_mask'], OPENMIC['sample_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 10, 128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192,  30, 176, 126, 208,  85,  84,  95,  69, 234,  99, 118, 166,\n",
       "       150, 106,  68, 165, 156, 146, 206,  75, 210, 131,  49,  61, 218,\n",
       "        92, 152, 121, 167,  62, 166, 167, 237,  22, 168, 165, 137, 178,\n",
       "       132, 196,  96,  54, 166, 169, 132,  59,  27,  46, 123,  89,  47,\n",
       "        58, 116,  48, 188, 157,  28,  44, 252, 248, 100,  28, 154, 147,\n",
       "       148, 204, 104,  95,  67, 109, 147, 204, 146, 196, 222,  90, 255,\n",
       "        94, 171,  53, 133, 202, 152,  35,  55, 231, 255,  62, 227, 168,\n",
       "       192,  87, 144, 130, 255,   0,   0, 163,  75, 255, 135, 216,  68,\n",
       "         0, 199,   0, 193, 254, 114,  12, 255,   0,  74, 165,   0, 201,\n",
       "       246,   0, 127, 211, 218, 164,  57, 238, 176, 158, 255])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features for the 9th time slice of 81st example\n",
    "X[80, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5    , 0.5    , 0.5    , 0.5    , 0.5    , 0.15055, 0.5    ,\n",
       "       0.5    , 0.5    , 0.5    , 0.5    , 0.5    , 0.5    , 0.5    ,\n",
       "       0.5    , 0.5    , 0.5    , 0.5    , 0.5    , 0.5    ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_true[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_mask[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000385_249600'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_key[40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the class map\n",
    "\n",
    "For convenience, we provide a simple JSON object that maps class indices to names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_ROOT, 'class-map.json'), 'r') as f:\n",
    "    class_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accordion': 0,\n",
       " 'banjo': 1,\n",
       " 'bass': 2,\n",
       " 'cello': 3,\n",
       " 'clarinet': 4,\n",
       " 'cymbals': 5,\n",
       " 'drums': 6,\n",
       " 'flute': 7,\n",
       " 'guitar': 8,\n",
       " 'mallet_percussion': 9,\n",
       " 'mandolin': 10,\n",
       " 'organ': 11,\n",
       " 'piano': 12,\n",
       " 'saxophone': 13,\n",
       " 'synthesizer': 14,\n",
       " 'trombone': 15,\n",
       " 'trumpet': 16,\n",
       " 'ukulele': 17,\n",
       " 'violin': 18,\n",
       " 'voice': 19}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the train-test splits\n",
    "\n",
    "OpenMIC-2018 comes with a pre-defined train-test split.  Great care was taken to ensure that this split is approximately balanced and artists are not represented in both sides of the split, so please use it!\n",
    "\n",
    "This is done by sample key, not row number, so you will need to go through the `sample_key` array to slice the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's split the data into the training and test set\n",
    "# We use squeeze=True here to return a single array for each, rather than a full DataFrame\n",
    "\n",
    "split_train = pd.read_csv(os.path.join(DATA_ROOT, 'partitions/split01_train.csv'), \n",
    "                          header=None).squeeze('columns')\n",
    "split_test = pd.read_csv(os.path.join(DATA_ROOT, 'partitions/split01_test.csv'), \n",
    "                         header=None).squeeze('columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      000046_3840\n",
       "1    000135_483840\n",
       "2    000139_119040\n",
       "3    000141_153600\n",
       "4     000144_30720\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These two tables contain the sample keys for training and testing examples\n",
    "# Let's see the keys for the first five training example\n",
    "split_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train: 14915,  # Test: 5085\n"
     ]
    }
   ],
   "source": [
    "# How many train and test examples do we have?  About 75%/25%\n",
    "print('# Train: {},  # Test: {}'.format(len(split_train), len(split_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "These sample key maps are easier to use as sets, so let's make them sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = set(split_train)\n",
    "test_set = set(split_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "Now that we have the sample keys for the training and testing examples, we need to partition the data arrays (`X`, `Y_true`, `Y_mask`).\n",
    "\n",
    "This is a little delicate to get right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These loops go through all sample keys, and save their row numbers\n",
    "# to either idx_train or idx_test\n",
    "#\n",
    "# This will be useful in the next step for slicing the array data\n",
    "idx_train, idx_test = [], []\n",
    "\n",
    "for idx, n in enumerate(sample_key):\n",
    "    if n in train_set:\n",
    "        idx_train.append(idx)\n",
    "    elif n in test_set:\n",
    "        idx_test.append(idx)\n",
    "    else:\n",
    "        # This should never happen, but better safe than sorry.\n",
    "        raise RuntimeError('Unknown sample key={}! Abort!'.format(sample_key[n]))\n",
    "        \n",
    "# Finally, cast the idx_* arrays to numpy structures\n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finally, we use the split indices to partition the features, labels, and masks\n",
    "X_train = X[idx_train]\n",
    "X_test = X[idx_test]\n",
    "\n",
    "Y_true_train = Y_true[idx_train]\n",
    "Y_true_test = Y_true[idx_test]\n",
    "\n",
    "Y_mask_train = Y_mask[idx_train]\n",
    "Y_mask_test = Y_mask[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14915, 10, 128)\n",
      "(5085, 10, 128)\n"
     ]
    }
   ],
   "source": [
    "# Print out the sliced shapes as a sanity check\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fit the models\n",
    "\n",
    "Now, we'll iterate over all the instrument classes, and fit a separate `XgBoost` model for each one.\n",
    "\n",
    "For each instrument, the steps are as follows:\n",
    "\n",
    "1. Find the subset of training (and testing) data that have been annotated for the current instrument\n",
    "2. Simplify the features to have one observation point per clip, instead of one point per time slice within each clip\n",
    "3. Initialize a classifier\n",
    "4. Fit the classifier to the training data\n",
    "5. Evaluate the classifier on the test data and print a report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Precision: 0.8054903761121777\n",
      "Average Test Recall: 0.784036490554956\n",
      "Average Test F1 Score: 0.7912780340484256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This dictionary will include the classifiers for each model\n",
    "models = dict()\n",
    "precision_lst = []\n",
    "recall_lst = []\n",
    "fscore_lst = []\n",
    "support_lst = []\n",
    "\n",
    "# We'll iterate over all istrument classes, and fit a model for each one\n",
    "# After training, we'll print a classification report for each instrument\n",
    "for instrument in tqdm(class_map):\n",
    "    \n",
    "    # Map the instrument name to its column number\n",
    "    inst_num = class_map[instrument]\n",
    "        \n",
    "    # Step 1: sub-sample the data\n",
    "    \n",
    "    # First, we need to select down to the data for which we have annotations\n",
    "    # This is what the mask arrays are for\n",
    "    train_inst = Y_mask_train[:, inst_num]\n",
    "    test_inst = Y_mask_test[:, inst_num]\n",
    "    \n",
    "    # Here, we're using the Y_mask_train array to slice out only the training examples\n",
    "    # for which we have annotations for the given class\n",
    "    X_train_inst = X_train[train_inst]\n",
    "    \n",
    "    # Step 3: simplify the data by averaging over time\n",
    "    \n",
    "    # Let's arrange the data for the model \n",
    "    # Instead of having time-varying features, we'll summarize each track by its mean feature vector over time\n",
    "    X_train_inst_sklearn = np.mean(X_train_inst, axis=1)\n",
    "    \n",
    "    # Again, we slice the labels to the annotated examples\n",
    "    # We thresold the label likelihoods at 0.5 to get binary labels\n",
    "    Y_true_train_inst = Y_true_train[train_inst, inst_num] >= 0.5\n",
    "\n",
    "    \n",
    "    # Repeat the above slicing and dicing but for the test set\n",
    "    X_test_inst = X_test[test_inst]\n",
    "    X_test_inst_sklearn = np.mean(X_test_inst, axis=1)\n",
    "    Y_true_test_inst = Y_true_test[test_inst, inst_num] >= 0.5\n",
    "\n",
    "    # Step 3.\n",
    "    # Initialize a new classifier\n",
    "    xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", max_depth=7, random_state=42, n_estimators=100)\n",
    "    \n",
    "    # Step 4.\n",
    "    xgb_model.fit(X_train_inst_sklearn, Y_true_train_inst)\n",
    "\n",
    "    # Step 5.\n",
    "    # Finally, we'll evaluate the model on both train and test\n",
    "    Y_pred_train = xgb_model.predict(X_train_inst_sklearn)\n",
    "    Y_pred_test = xgb_model.predict(X_test_inst_sklearn)\n",
    "    \n",
    "    # print('-' * 52)\n",
    "    # print(instrument)\n",
    "    # print('\\tTRAIN')\n",
    "    # print(classification_report(Y_true_train_inst, Y_pred_train))\n",
    "    # print('\\tTEST')\n",
    "    # print(classification_report(Y_true_test_inst, Y_pred_test))\n",
    "    \n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(Y_true_test_inst, Y_pred_test, average='macro')\n",
    "    precision_lst = precision_lst + [precision]\n",
    "    recall_lst = recall_lst + [recall]\n",
    "    fscore_lst = fscore_lst + [fscore]\n",
    "    \n",
    "    # Store the classifier in our dictionary\n",
    "    models[instrument] = xgb_model\n",
    "print(f'Average Test Precision: {np.mean(precision_lst)}')\n",
    "print(f'Average Test Recall: {np.mean(recall_lst)}')\n",
    "print(f'Average Test F1 Score: {np.mean(fscore_lst)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping up\n",
    "\n",
    "So the predictions here are definitely not perfect, but they're a good start!\n",
    "\n",
    "Some things you might want to try out:\n",
    "\n",
    "1. Instead of averaging features over time, apply the classifiers to each time-step to get a time-varying instrument detector.\n",
    "2. Play with the parameters of the `XgBoost` model, changing the depth and number of estimators.\n",
    "3. Run the trained model on your own favorite songs!\n",
    "4. Train a different model, maybe using different features!\n",
    "5. Make use of label uncertainties or unlabeled data when training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
